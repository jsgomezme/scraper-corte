# Scraper Corte Constitucional Colombia

Scraper automatizado para extraer comunicados de la Corte Constitucional de Colombia y enviarlos a n8n.

## ğŸ¯ Objetivo

Automatizar el scraping de comunicados desde la pÃ¡gina oficial de la Corte Constitucional de Colombia y enviar esa informaciÃ³n a un flujo de n8n en la nube, cada 10 minutos.

## ğŸ—ï¸ Arquitectura

- **Google Cloud Run**: Servicio sin servidor para ejecutar el scraper
- **Puppeteer**: Navegador headless para scraping
- **Express**: Servidor web para endpoints
- **n8n**: Plataforma de automatizaciÃ³n para procesar los datos

## ğŸ“ Estructura del Proyecto

```
scraper-corte/
â”œâ”€â”€ scraper.js          # LÃ³gica principal del scraper
â”œâ”€â”€ package.json        # Dependencias del proyecto
â”œâ”€â”€ Dockerfile          # ConfiguraciÃ³n para Cloud Run
â””â”€â”€ README.md           # Este archivo
```

## ğŸš€ Endpoints Disponibles

### `/health`
Verifica que el servicio estÃ© funcionando.
```bash
GET https://tu-servicio.run.app/health
```

### `/test`
Prueba la conexiÃ³n con el webhook de n8n.
```bash
GET https://tu-servicio.run.app/test
```

### `/`
Ejecuta el scraping principal y envÃ­a datos a n8n.
```bash
GET https://tu-servicio.run.app/
```

## ğŸ“Š Formato de Datos

Los datos se envÃ­an a n8n en el siguiente formato:

```json
{
  "comunicados": [
    {
      "indice": 1,
      "titulo": "TÃ­tulo del comunicado",
      "fecha": "Fecha de publicaciÃ³n",
      "documento": "URL del documento"
    }
  ],
  "timestamp": "2024-01-01T00:00:00.000Z",
  "cantidad": 10,
  "source": "Corte Constitucional Colombia",
  "url": "https://www.corteconstitucional.gov.co/comunicados"
}
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

- `PORT`: Puerto del servidor (default: 8080)
- `WEBHOOK_URL`: URL del webhook de n8n (configurada en el cÃ³digo)

### Webhook de n8n

El webhook debe estar configurado en n8n para recibir datos POST en:
```
https://lab.irradialab.com/webhook/recibir-comunicados
```

## ğŸš€ Despliegue en Google Cloud Run

1. **Subir cÃ³digo a GitHub**
2. **Conectar repositorio con Cloud Run**
3. **Configurar variables de entorno**
4. **Desplegar automÃ¡ticamente**

## â° ProgramaciÃ³n con Cloud Scheduler

Configurar un job que ejecute cada 10 minutos:
- **URL**: `https://tu-servicio.run.app/`
- **MÃ©todo**: GET
- **Frecuencia**: `*/10 * * * *`

## ğŸ” DiagnÃ³stico

### Verificar que el servicio funciona
```bash
curl https://tu-servicio.run.app/health
```

### Probar el webhook
```bash
curl https://tu-servicio.run.app/test
```

### Ejecutar scraping manual
```bash
curl https://tu-servicio.run.app/
```

## ğŸ“ Logs

Los logs se pueden ver en Google Cloud Console:
1. Ir a Cloud Run
2. Seleccionar el servicio
3. Ir a la pestaÃ±a "Logs"

Los logs incluyen emojis para facilitar la identificaciÃ³n:
- ğŸ¥ Health check
- ğŸ§ª Prueba de webhook
- ğŸš€ Inicio de scraping
- âœ… Operaciones exitosas
- âŒ Errores

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Node.js**: Runtime de JavaScript
- **Puppeteer**: Navegador headless
- **Express**: Framework web
- **Axios**: Cliente HTTP
- **Docker**: ContenedorizaciÃ³n
- **Google Cloud Run**: Plataforma de ejecuciÃ³n

## ğŸ“ Soporte

Para problemas o consultas, revisar los logs en Google Cloud Console. 